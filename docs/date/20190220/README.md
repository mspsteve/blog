---
sidebarDepth: 0
---

# 春节项目总结

[[toc]]

## 踩过的坑、解决问题总结

### 日志打印
:::tip
- perf log 日志打印过程中，PerfUtils.perf 在使用的过程中，不要使用变量(测试环境 遇到bug,导致`OOM`)
- 如果非要传变量统计，请使用:
     `PerfUtils.perf(TAG, SUB_TAG_RED_PACKET_INSERT_PAY).millis(payRecord.getCreateTime())`在mills中传参，根据具体情况统计；
:::


### 上线相关

- 任何线上变动 一定要先灰度观察，然后再上线或者重启；
- 非标准runner、sdk、api,需要找王至前新建jenkins项目，遇到的坑

::::warning
jenkins 两个api同时勾选打包，会被新的api覆盖掉老的API(已经修复)
::::

### 业务对接

- 被调用方
 对接任何上下游系统，一定要了解：入参、返回值、正确的调用方式、接口响应时间、同步异步、是否存在降级策略、
              具体功能、实现原理、服务挂掉对业务的影响；
- 调用方：是否存在服务限流，是否存在响应超时处理预案、监控是否完善(区分各种异常情况)；

### 资源相关

- 资源申请环境：测试发现问题、预演解决bug(测试账号)、线上压测发现问题、code review尽可能确认表结构，避免大的改动
- 资源预估环节：根据压测结果*2倍去申请资源，基本上不会存在问题
- mysql资源：mysql索引创建要根据数据分布去创建
- kafka资源：
  - 需要自己新建kafka集群，默认消费就就近消费，单机房部署也可以消费其他机房的kafka,部署机器数量：
    :::tip
    最优部署> n+1 n表示kafka partition数量
    :::
  - 数据同步需要自己新建同步的topic,即离线的集群，然后在数据同步平台新建同步到hive的job
    ::::warning
       数据同步平台要求同步kafka topic 对应的partition下一个时刻全部有数据写入，才会同步上一个时刻的数据
    ::::

- kcs部署：要确保配置日志路径正确，kcs重新部署会重新分配机器+端口号，如果需要排查问题 && 知道物理机，则可以申请权限去查询
             错误路径则无法实现日志归档

### 相关指标

- 数据库相关：数据库 tps承载量、数据库所在机器CPU、内存、数据库的连接数、数据库主从同步延迟、SQL执行时间：基本上均为ms级别，接近s级别和s级以上需要排查原因；
- redis相关：redis查询量，redis命中率，以及相关操作是否符合代码中出现频次，redis查询时间基本上都是ms或者更小，有值比较大时需要排查问题
- 机器相关：看看CPU使用率，young gc full gc发生频率，结合代码中的操作，确定CPU核数 或者相关参数大小：-Xms8G -Xss256k -Xmn4G -Xmx10G
- 压测相关：   对压测和公演环境出现的问题一定要深究，提前解决掉出现的问题，相关监控 要尽可能提前完善

### code相关

- 追求简洁高效的处理方案，结合具体业务
- 使用公司框架之前要彻底了解原理后再使用
- 谢绝使用lombok:原因是会插入代码，排查问题时，无法准确定位代码行号
- 相关变量：必须可配置，避免出现写死的情况，和前端需要交互的内容则由后端下发

## 个人能力

- mysql、redis的实际应用知识点不全面，缺少排查问题的思路
- 代码质量相关：拒绝出现低级错误
- 相关linux命令不熟悉，导致排查问题太慢
- 灾备意识不强，对任何操作要有回滚操作和灾备方案，要对自己的所有操作有兜底预案